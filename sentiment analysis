{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emanimair/sentiment-analysis?scriptVersionId=251191191\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## 📌 Introduction\n\nIn today's data-driven world, understanding and extracting insights from **unstructured text data**—such as customer reviews—has become paramount for businesses aiming to enhance customer satisfaction and improve their products or services.\n\nThis project focuses on leveraging **sentiment analysis** to classify **Amazon reviews** as **positive**, **negative**, or **neutral**, providing valuable insights into customer opinions and sentiments.\n","metadata":{}},{"cell_type":"markdown","source":"## 🎯 Objective\n\nThe primary objective of this project is to develop an **automated sentiment analysis system** capable of accurately determining the **sentiment** expressed in **Amazon customer reviews** by employing **Natural Language Processing (NLP)** techniques.\n","metadata":{}},{"cell_type":"markdown","source":"## 🛠️ Methodology\n\n### 1. **Data Collection**\nThe dataset used in this project was collected from **Amazon customer reviews**.\n\n---\n\n### 2. **Data Preparation**\n\nTasks include:\n\n- **2.1** Loading and reading the dataset  \n- **2.2** Cleaning and transforming the data to ensure high-quality input for analysis\n\n---\n\n### 3. **Preprocessing**\n\nSeveral preprocessing steps were undertaken:\n\n- **3.1** Tokenization  \n- **3.2** Stop-word removal  \n- **3.3** Stemming/Lemmatization  \n\nThese steps help **standardize** the text and **reduce noise**.\n\n---\n\n### 4. **Sentiment Analysis**\n\nThe final step involves classifying each review as:\n\n- **Positive**\n- **Negative**\n- **Neutral**\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from twython import Twython\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T12:35:46.043434Z","iopub.execute_input":"2025-07-18T12:35:46.043839Z","iopub.status.idle":"2025-07-18T12:35:46.049653Z","shell.execute_reply.started":"2025-07-18T12:35:46.043806Z","shell.execute_reply":"2025-07-18T12:35:46.048368Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Importing the Important Libraries \nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport nltk\n\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:46.051733Z","iopub.execute_input":"2025-07-18T12:35:46.052135Z","iopub.status.idle":"2025-07-18T12:35:47.970504Z","shell.execute_reply.started":"2025-07-18T12:35:46.052098Z","shell.execute_reply":"2025-07-18T12:35:47.969194Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"file_path=\"/kaggle/input/amazon-fine-food-reviews/Reviews.csv\"","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:47.972491Z","iopub.execute_input":"2025-07-18T12:35:47.97289Z","iopub.status.idle":"2025-07-18T12:35:47.978142Z","shell.execute_reply.started":"2025-07-18T12:35:47.972855Z","shell.execute_reply":"2025-07-18T12:35:47.977013Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#load the dataset into a dataframe\ndataset=pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:47.979708Z","iopub.execute_input":"2025-07-18T12:35:47.98011Z","iopub.status.idle":"2025-07-18T12:35:57.415795Z","shell.execute_reply.started":"2025-07-18T12:35:47.980074Z","shell.execute_reply":"2025-07-18T12:35:57.414225Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#read the first 5 rows of the dataset\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:57.418442Z","iopub.execute_input":"2025-07-18T12:35:57.41899Z","iopub.status.idle":"2025-07-18T12:35:57.44871Z","shell.execute_reply.started":"2025-07-18T12:35:57.418942Z","shell.execute_reply":"2025-07-18T12:35:57.447424Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#check the dataset shape \ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:57.450028Z","iopub.execute_input":"2025-07-18T12:35:57.450427Z","iopub.status.idle":"2025-07-18T12:35:57.458798Z","shell.execute_reply.started":"2025-07-18T12:35:57.450382Z","shell.execute_reply":"2025-07-18T12:35:57.457496Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(568454, 10)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":" <h5 syle=\"solor:#183D3D\"> The Data Set Contain of [568454] Rows and [5] Columns</h5> ","metadata":{}},{"cell_type":"code","source":"#dataset columns name \ndataset.columns","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:57.460413Z","iopub.execute_input":"2025-07-18T12:35:57.460787Z","iopub.status.idle":"2025-07-18T12:35:57.481678Z","shell.execute_reply.started":"2025-07-18T12:35:57.460752Z","shell.execute_reply":"2025-07-18T12:35:57.480377Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n      dtype='object')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#check the missing  values  in the dataset\ndataset.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:57.483357Z","iopub.execute_input":"2025-07-18T12:35:57.483838Z","iopub.status.idle":"2025-07-18T12:35:58.005594Z","shell.execute_reply.started":"2025-07-18T12:35:57.483797Z","shell.execute_reply":"2025-07-18T12:35:58.004004Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Id                         0\nProductId                  0\nUserId                     0\nProfileName               16\nHelpfulnessNumerator       0\nHelpfulnessDenominator     0\nScore                      0\nTime                       0\nSummary                   27\nText                       0\ndtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dataset.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:58.007407Z","iopub.execute_input":"2025-07-18T12:35:58.00791Z","iopub.status.idle":"2025-07-18T12:35:58.517715Z","shell.execute_reply.started":"2025-07-18T12:35:58.007861Z","shell.execute_reply":"2025-07-18T12:35:58.516256Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"43"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#consider the most important columns for this project \ndataset = dataset[['Id', 'ProductId', #'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       #'HelpfulnessDenominator',\n                   'Score', #'Time',\n                   #'Summary'\n                    'Text']].copy()","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:58.519473Z","iopub.execute_input":"2025-07-18T12:35:58.519981Z","iopub.status.idle":"2025-07-18T12:35:58.611382Z","shell.execute_reply.started":"2025-07-18T12:35:58.519927Z","shell.execute_reply":"2025-07-18T12:35:58.609513Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:58.615497Z","iopub.execute_input":"2025-07-18T12:35:58.616093Z","iopub.status.idle":"2025-07-18T12:35:58.624675Z","shell.execute_reply.started":"2025-07-18T12:35:58.616031Z","shell.execute_reply":"2025-07-18T12:35:58.623234Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(568454, 4)"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## 🧠 How Sentiment Analysis Works\n\n### 1. **Tokenization**  \nThe first step is to divide the text into **tokens**, which are individual words or phrases. Each token is assigned a standardized format for processing.\n\n### 2. **Polarity Score Calculation**  \nFor each text, a **polarity score** is calculated. This score can include the following components:\n\n- **Positive (Pos):** Indicates a positive sentiment.  \n- **Negative (Neg):** Indicates a negative sentiment.  \n- **Neutral (Neu):** Indicates a neutral sentiment.  \n- **Compound (Comp):** A composite value that represents the overall sentiment of the text by combining positive, negative, and neutral elements.\n\nThe **Pos** score reflects the degree of positivity in the text, the **Neg** score indicates negativity, and the **Neu** score captures neutral tone. The **Comp** score provides an overall sentiment assessment:\n- **Positive Comp values** → positive sentiment  \n- **Negative Comp values** → negative sentiment\n","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nfrom tqdm.notebook import tqdm #to loop through the dataset row by row \n\nsia = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:58.62657Z","iopub.execute_input":"2025-07-18T12:35:58.627675Z","iopub.status.idle":"2025-07-18T12:35:58.677438Z","shell.execute_reply.started":"2025-07-18T12:35:58.627563Z","shell.execute_reply":"2025-07-18T12:35:58.67606Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# find the polarity score on the entire dataset\n#this will get a dictionary contain the [ID  ,neg, neu , pos ,comp ]\nres = {}\nfor i, row in tqdm(dataset.iterrows(), total=len(dataset)):\n    text = row['Text']\n    myid = row['Id']\n    res[myid] = sia.polarity_scores(text)","metadata":{"execution":{"iopub.status.busy":"2025-07-18T12:35:58.679002Z","iopub.execute_input":"2025-07-18T12:35:58.679447Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/568454 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1830da6190476797908ab9ff798c09"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#show the polarity score for each text \nres","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#conver res to dataframe called vasders then merge vaders dataframe with the whole dataset through the Id column \nvaders = pd.DataFrame(res).T\nvaders = vaders.reset_index().rename(columns={'index': 'Id'})\nvaders = vaders.merge(dataset, how='left')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vaders.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot VADER results \nfig, axs = plt.subplots(1, 3, figsize=(12, 3))\nsns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])\nsns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])\nsns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])\naxs[0].set_title('Positive')\naxs[1].set_title('Neutral')\naxs[2].set_title('Negative')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}